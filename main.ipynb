{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd957d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "from fastprogress.fastprogress import IN_NOTEBOOK\n",
    "from datasets import load_from_disk, load_metric, load_dataset\n",
    "from transformers import AutoTokenizer, BartConfig\n",
    "from architectures import Autoencoder, CBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d81aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_NOTEBOOK:\n",
    "    class CustomArgs():\n",
    "        batch_size = 8\n",
    "        exp_name = \"384-1024\"\n",
    "        checkpoint_dir = \"./cbart-checkpoints/384\"\n",
    "        first = 576\n",
    "        second = 480\n",
    "        third = 384\n",
    "        test = True\n",
    "    \n",
    "    args = CustomArgs()\n",
    "\n",
    "else:    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--checkpoint_dir', type=str, help=\"The cBART model directory.\", required=True)\n",
    "    parser.add_argument('--exp_name', type=str, help=\"The experiment name.\", required=True)\n",
    "    parser.add_argument('--batch_size', type=int, help=\"The batch_size.\", required=True)\n",
    "    parser.add_argument('--first', type=int, help=\"The AE's first projection.\", required=True)\n",
    "    parser.add_argument('--second', type=int, help=\"The AE's second projection.\", required=True)\n",
    "    parser.add_argument('--third', type=int, help=\"The AE's third projection.\", required=True)\n",
    "    parser.add_argument('--test', action='store_true', help=\"A test run with just one sample.\")\n",
    "\n",
    "    args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c8cbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_checkpoint    = 'facebook/bart-base'\n",
    "encoder_max_length = 1024\n",
    "log_directory      = os.path.join(\"./results/\", args.exp_name)\n",
    "\n",
    "os.makedirs(log_directory, exist_ok=True)\n",
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a0fbd4",
   "metadata": {},
   "source": [
    "# The AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203c5d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(bart_encoder_emb_size=768,\n",
    "                 first_proj=args.first,\n",
    "                 second_proj=args.second,\n",
    "                 third_proj=args.third,\n",
    "                 max_len=encoder_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289be61",
   "metadata": {},
   "source": [
    "# Initialize compressedBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2217ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbart_config = BartConfig.from_pretrained(bart_checkpoint)\n",
    "cbart_config.enc_d_model = cbart_config.d_model\n",
    "cbart_config.d_model = args.third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20bc237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CBartForConditionalGeneration were not initialized from the model checkpoint at ./cbart-checkpoints/384 and are newly initialized: ['model.encoder.ae.encoder.1.bias', 'model.encoder.ae.encoder.7.bias', 'model.encoder.ae.decoder.4.num_batches_tracked', 'model.encoder.ae.encoder.1.weight', 'model.encoder.ae.decoder.7.running_mean', 'model.encoder.ae.decoder.4.running_mean', 'model.encoder.ae.encoder.0.weight', 'model.encoder.ae.encoder.7.weight', 'model.encoder.ae.encoder.7.running_var', 'model.encoder.ae.decoder.6.weight', 'model.encoder.ae.decoder.1.running_var', 'model.encoder.ae.decoder.7.running_var', 'model.encoder.ae.encoder.7.num_batches_tracked', 'model.encoder.ae.encoder.7.running_mean', 'model.encoder.ae.encoder.4.running_var', 'model.encoder.ae.encoder.4.bias', 'model.encoder.ae.decoder.7.bias', 'model.encoder.ae.encoder.1.running_var', 'model.encoder.ae.decoder.7.weight', 'model.encoder.ae.encoder.4.running_mean', 'model.encoder.ae.decoder.1.weight', 'model.encoder.ae.encoder.3.weight', 'model.encoder.ae.decoder.0.weight', 'model.encoder.ae.decoder.1.running_mean', 'model.encoder.ae.decoder.1.bias', 'model.encoder.ae.decoder.1.num_batches_tracked', 'model.encoder.ae.decoder.3.weight', 'model.encoder.ae.decoder.4.running_var', 'model.encoder.ae.decoder.4.bias', 'model.encoder.ae.encoder.1.num_batches_tracked', 'model.encoder.ae.encoder.6.weight', 'model.encoder.ae.encoder.4.weight', 'model.encoder.ae.decoder.4.weight', 'model.encoder.ae.encoder.1.running_mean', 'model.encoder.ae.decoder.7.num_batches_tracked', 'model.encoder.ae.encoder.4.num_batches_tracked']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "CBart_model = CBartForConditionalGeneration.from_pretrained(args.checkpoint_dir,\n",
    "                                                            config=cbart_config,\n",
    "                                                            ae=ae,\n",
    "                                                            ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e9b13f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weights and put it on GPU\n",
    "ae_checkpoint = os.path.join( args.checkpoint_dir, \"ae-checkpoint.pth\" )\n",
    "if torch.cuda.is_available():\n",
    "    ae_checkpoint = torch.load(ae_checkpoint)\n",
    "\n",
    "else:\n",
    "    ae_checkpoint = torch.load(ae_checkpoint, map_location=torch.device('cpu'))\n",
    "\n",
    "CBart_model.model.encoder.ae.load_state_dict(ae_checkpoint['model'])\n",
    "del ae_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52d061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBart_model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    CBart_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db6438",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61810824",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(bart_checkpoint, cache_dir=\"./hf-cache/bart-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abfa9bd",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df82db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_from_disk( '../../hf-cache/cnn_dailymail/{}'.format('test') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ab75a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = load_dataset(\"ccdv/cnn_dailymail\", \"3.0.0\", cache_dir=\"./hf-cache/cnn_dailymail\",\n",
    "#                              split=\"test\", ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c8941ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.test:\n",
    "    test_dataset = test_dataset.select(range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d63c2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(batch):\n",
    "    inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=encoder_max_length, return_tensors=\"pt\", truncation=True)\n",
    "    input_ids = inputs_dict.input_ids\n",
    "    attention_mask = inputs_dict.attention_mask\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.to(\"cuda\")\n",
    "        attention_mask = attention_mask.to(\"cuda\")\n",
    "\n",
    "    predicted_abstract_ids = CBart_model.generate(input_ids, attention_mask=attention_mask, use_cache=True)\n",
    "    batch[\"predicted_highlights\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339015b2",
   "metadata": {},
   "source": [
    "# Decoding Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a2112c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function generate_summary at 0x2b991aeef790> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f50a130d2d14a73b254dd0cdfc0ee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set decoding params\n",
    "CBart_model.config.max_length = 144\n",
    "CBart_model.config.min_length = 55\n",
    "CBart_model.config.no_repeat_ngram_size = 3\n",
    "CBart_model.config.early_stopping = True\n",
    "CBart_model.config.length_penalty = 2.0\n",
    "CBart_model.config.num_beams = 4\n",
    "    \n",
    "result = test_dataset.map(generate_summary, batched=True, batch_size=args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9151ed01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'James Best played Rosco P. Coltrane on \"The Dukes of Hazzard\"\\nHe was 88.\\nHe died in hospice in North Carolina, of complications from pneumonia.\\nBest was best known for his role, which still lives on in reruns.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]['predicted_highlights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9576ddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1\n",
      "0.382\n",
      "rouge2\n",
      "0.152\n",
      "rouge3\n",
      "0.094\n",
      "rougeLsum\n",
      "0.353\n"
     ]
    }
   ],
   "source": [
    "if not IN_NOTEBOOK:\n",
    "    result.to_csv( os.path.join(log_directory, 'beam.csv') )\n",
    "\n",
    "beam_scores = rouge.compute(predictions=result[\"predicted_highlights\"], references=result[\"highlights\"],\n",
    "                            rouge_types=[\"rouge1\", \"rouge2\", \"rouge3\", \"rougeLsum\"])\n",
    "    \n",
    "for item, score in beam_scores.items():\n",
    "    print(item)\n",
    "    print(\"{:.3f}\".format(score.mid.fmeasure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d7cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
